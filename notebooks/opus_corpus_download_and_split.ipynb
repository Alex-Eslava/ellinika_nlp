{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f24170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opustools\n",
    "import pandas as pd\n",
    "import xml.etree.cElementTree as et\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f9c75a7",
   "metadata": {},
   "source": [
    "# Run this to download corpuses from opus\n",
    "opus_getter = opustools.OpusGet(\n",
    "    directory='WikiMatrix',\n",
    "    source = 'el',\n",
    "    target = 'ca',\n",
    "    preprocess='xml'\n",
    ")\n",
    "# Downloads source+target languages for directory-named corpus\n",
    "# Files come compressed\n",
    "opus_getter.get_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9683827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opus_directory = 'WikiMatrix'\n",
    "languages = ['EL', 'CA']\n",
    "output_data = pd.DataFrame()\n",
    "\n",
    "raw_data_path = \"../data/raw/\"\n",
    "opus_directory = 'WikiMatrix'\n",
    "\n",
    "for lang in languages:\n",
    "    print(f\"Going for {lang}\")\n",
    "    file = raw_data_path + opus_directory + '/xml/' + lang.lower() + '/WikiMatrix.xml'\n",
    "    xtree = et.parse(file)\n",
    "    xroot = xtree.getroot()\n",
    "    rows = []\n",
    "    df_cols = lang\n",
    "    for node in xroot:\n",
    "        full_string = ''\n",
    "        for word in node.iter():\n",
    "            if word.text is None:\n",
    "                continue\n",
    "            else: \n",
    "                full_string = full_string + ' ' + word.text\n",
    "        rows.append(full_string)\n",
    "    output_data[lang] = rows\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e1b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_path = '../data/interim/opus_corpus/'\n",
    "filename_core = opus_directory.lower()\n",
    "filename_langs = '_'.join(languages)\n",
    "filename = filename_core + filename_langs.lower() + '.tsv'\n",
    "output_path = output_folder_path + filename\n",
    "# Store as .tsv\n",
    "output_data.to_csv(output_path, sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b95ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(output_data, test_size = 0.2, random_state=42)\n",
    "train, dev = train_test_split(train, test_size = 0.25, random_state=42) # 0.25 * 0.8 = 0.2\n",
    "\n",
    "train.to_csv(output_folder_path+'train_'+ filename, sep = '\\t', index=False)\n",
    "test.to_csv(output_folder_path+'test_'+ filename, sep = '\\t', index=False)\n",
    "dev.to_csv(output_folder_path+'dev_'+ filename, sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182ed621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
